
TIME COMPLEXITY ANALYSIS
Note :  1. The time complexity is explained with respect to the pseudo codes.
             2. A – Unsorted array
             3. n – number of elements	

1.	Selection Sort
Pseudo code :

Selection_Sort(A,n)
{
	for i ← 0 to n-2
	{
		iMin ← i	          c1 ← (n-1)
		for j←i+1 to n-1
		{
			if(A[j]<A[min]) 		
				iMin←j	      	c2 ← ∑ (n-1)
		}
	temp←A[i]
A[i]←A[iMin]	          c3 ← (n-1)
A[iMin]←temp
}
	}
 Time Complexity :
	T(n) = c1 + c2 + c3
	       = (n-1) + (n(n-2))/2 + (n-1)
 We get an equation of the form :
               an2 + bn + c  where a,b,c are constants.
	We consider only n2 and the lower order terms can be ignored.
It should be noted that the time complexity of Selection Sort  is O(n2) i.e  Big-Oh(n2) in all cases.


2.	Insertion Sort:
Pseudo code :

Insertion_Sort(A,n)
{
	for i ← 1 to n-1
	{
		key  ←A[ i]		
		pos ← i		                          c1 ← (n-1)
while(pos > 0   &&  A[pos-1]>key)
		{
			A[pos] ← A[pos-1]) 		
			pos ← pos-1	                     	c2 
		}
	A[pos] ← key                         	c3 ← (n-1)
}
	}
 Time Complexity :
1.	Best Case :
For the best case, where the array elements are already sorted , the program does not enter the while loop, so c2 will take a value of 0 (c2=0).
Therefore we have,
	
	T(n)= c1+c3
	       = (n-1)+(n-1)
 From the equation we can observe that the highest order term in the equation is n and hence the time complexity of Insertion Sort in best case is Ω(n).

2.	Worst Case and Average Case : 
The term c2 will take a value of ∑ (n-1).
Then we have, 	
T(n) = c1 + c2 + c3
	       = (n-1) + (n(n-2))/2 + (n-1)
 We get an equation of the form :
               an2 + bn + c  where a,b,c are constants.
	We consider only n2 and the lower order terms can be ignored.
The time complexity of Insertion Sort  is O(n2) i.e  Big-Oh(n2)

3.	Merge Sort :
L – the left most index of the Array
R – the right most index of the Array

Pseudo Code :

Merge(L,R,A)
{
	nL ← length(L)
	nR ← length(R)
 	
	i←0     //smallest unpicked in L
	j←0    // smallest unpicked in R
	k←0

	while( i<nL  &&  j<nR)
	{
		if( L[i] <= R[j] )
		{
			A[k] ← L[i]
			k←k+1
			i←i+1
		}
		else
		{
			A[k] ← R[j]
			k←k+1
			j←j+1	
		}
	}

	while( i<nL )
	{
		A[k] ← L[i]
		k←k+1
		i←i+1
	}

	while(j<nR )
	{
		A[k] ← R[i]
		k←k+1
		j←j+1
	}
}



MergeSort(A)
{
	n←length(A)
	if(n<2)
	     return
	mid←n/2
             
left←array_of_size(mid)
right←array_of_size(n-mid)

for i←0 to mid-1
	left[i]←A[i]
for j←mid to n-1
	right[j]←A[i]

MergeSort(left)
MergeSort(right)
Merge(left,right,n)
	}
 	Recursion Tree :
	 



Time Complexity using Iteration Method :
define T(n) = the worst-case time to execute mergesort on a list of n elements proceed in 2 steps
(i)	assume n = 2k for an integer k 
T(n) =     1                       n = 1
               n + 2T(n/2)      n > 1 

T(n) = n + 2T(n/2)						 [by the recurrence]  
        = n + 2(n/2) + 4T(n/4)                                                    [substituting for T(n/2)] 
        = n + 2(n/2) + 4(n/4) + 8T(n/8)                                           [substituting for T(n/4)]                                                                        
          = n + 2(n/2) + 4(n/4) + ... + 2i-1 (n/2i-1 ) + 2iT(n/2 i )              [generalizing]			          
          = n + 2(n/2) + ... + 2i (n/2 i ) + ... + 2k−1 (n/2 k−1 ) + 2k           [take i = k & use base case]
          = n(1 + k)
          = n(1 + log n)
thus T(n) = O(n log n),
 for n a power of 2 this calculation is the iteration method

(ii)	 let n be arbitrary Fact. There is a power of 2 between n and 2n (specifically p = 2⌈ log n⌉ ). for the above power p, T(n) ≤ T(p) = p(1 + log p) ≤ 2n(1 + log 2n) =⇒ in general, 
T(n) = O(n log n) 






4.	Bubble Sort
Pseudo code :

Bubble_Sort(A,n)
{
	for i ← 1 to (n-1)	
	{
		for j ← 0  && (n-2) 	   
		{
			if (A[j]<A[j+1]) 		
				swap(A[j], A[j+1]	        c1 ←  (n-1) * (n-1)
		}
	}
	}
 Time Complexity :
1.	Best Case : 
For the best case, where the array elements are already sorted , the program does not enter the while loop, so the external for loop is executed n times, and we get the complexity of Ω(n).

2.	Worst Case and Average Case :
	T(n) = c * (n-1) * (n-1)
 We get an equation of the form :
               an2 + bn + c  where a,b,c are constants.
	We consider only n2 and the lower order terms can be ignored.
It should be noted that the time complexity of Bubble Sort  is O(n2) i.e  Big-Oh(n2) in all cases.







 
